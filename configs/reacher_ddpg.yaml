# Environment parameters

unity_env_path: ./Reacher_Linux/Reacher.x86_64
env: reacher
state_size: 33
action_size: 4
action_min: -1
action_max: 1
num_agents: 20
random_seed: 2

# Training parameters

model: ddpg
device: cuda
n_episodes: 500
batch_size: 128
replay_mem_size: 1000000 # maximum capacity of replay memory
gamma: 0.99 # Discount rate (gamma) for future rewards

# Network parameters

critic_lr: 0.001
actor_lr: 0.001
fc_layers: [ 256, 128 ]
final_layer_init: 0.003
tau: 0.001 # parameter for soft target network updates
update_every: 10
target_update_every: 2
learning_steps: 20
gradient_clipping: true

# Miscellaneous
results_path: results

