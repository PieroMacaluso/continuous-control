# Environment parameters

unity_env_path: ./Reacher_Linux/Reacher.x86_64
env: reacher
state_size: 33
action_size: 4
action_min: -1
action_max: 1
num_agents: 20
random_seed: 4

# Training parameters

model: ddpg
device: cuda
n_episodes: 500
batch_size: 256
replay_mem_size: 1000000 # maximum capacity of replay memory
gamma: 0.99 # Discount rate (gamma) for future rewards

# Network parameters

critic_lr: 0.001
actor_lr: 0.001
actor_layers: [ 128, 128 ]
critic_layers: [ 128, 128 ]
final_layer_init: 0.003
tau: 0.001 # parameter for soft target network updates
update_every: 20
target_update_every: 10
learning_steps: 10
gradient_clipping_critic: true
gradient_clipping_actor: false

# Miscellaneous
results_path: results

